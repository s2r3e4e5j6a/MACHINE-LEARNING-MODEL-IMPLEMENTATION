# -*- coding: utf-8 -*-
"""
# Spam Email Detection using Scikit-learn

This script demonstrates the implementation of a predictive model for spam email detection.
We will use a synthetic dataset, preprocess the text data, train a Multinomial Naive Bayes classifier,
and evaluate its performance.

## 1. Import Necessary Libraries
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

"""
## 2. Generate/Load Dataset

For demonstration purposes, we'll create a small synthetic dataset of emails and their labels (spam/ham).
In a real-world scenario, you would load your dataset from a CSV file, database, etc.
"""

data = {
    'email_text': [
        "Congratulations! You've won a free iPhone. Click here to claim.",
        "Hey, how are you doing? Let's catch up soon.",
        "Urgent: Your bank account has been compromised. Verify your details now!",
        "Meeting reminder for tomorrow at 10 AM.",
        "Limited time offer! Get rich quick with our new investment plan.",
        "Hi team, please find the updated project report attached.",
        "Claim your prize money! Send your bank details immediately.",
        "Just wanted to check in and see if you received my last email.",
        "Viagra pills for sale. Best prices!",
        "Don't miss out on this incredible deal!",
        "Regarding the document you requested.",
        "Free gift card! Enter your credit card details.",
        "Your Amazon order has shipped.",
        "Exclusive discount code for loyal customers.",
        "You have a new message from a secret admirer.",
        "Please review the attached invoice.",
        "Win a lottery! Reply with your personal information.",
        "Looking forward to our call next week.",
        "Earn thousands from home. No experience needed!",
        "Project deadline extended to Friday."
    ],
    'label': [
        'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam',
        'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham'
    ]
}

df = pd.DataFrame(data)
print("--- Sample Dataset ---")
print(df.head())
print("\n--- Label Distribution ---")
print(df['label'].value_counts())

"""
## 3. Data Preprocessing

Text data needs to be converted into numerical features that a machine learning model can understand.
We will use `CountVectorizer` to convert a collection of text documents to a matrix of token counts.
"""

# Convert labels to numerical format (0 for ham, 1 for spam)
df['label_numeric'] = df['label'].apply(lambda x: 1 if x == 'spam' else 0)

# Split data into features (X) and target (y)
X = df['email_text']
y = df['label_numeric']

# Split the dataset into training and testing sets
# test_size=0.2 means 20% of the data will be used for testing
# random_state ensures reproducibility of the split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\nTraining set size: {len(X_train)} samples")
print(f"Testing set size: {len(X_test)} samples")

# Initialize CountVectorizer
# It converts a collection of text documents to a matrix of token counts.
vectorizer = CountVectorizer()

# Fit the vectorizer on the training data and transform both training and testing data
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

print("\n--- Vectorized Training Data Shape ---")
print(X_train_vectorized.shape)
print("\n--- Sample of Vectorized Training Data (first 5 rows) ---")
# Note: For large datasets, avoid converting toarray() as it can consume a lot of memory.
# This is fine for small synthetic data.
print(X_train_vectorized.toarray()[:5])

"""
## 4. Model Selection and Training

For text classification, Multinomial Naive Bayes is a commonly used and effective algorithm,
especially with count-based features like those generated by `CountVectorizer`.
"""

# Initialize the Multinomial Naive Bayes classifier
model = MultinomialNB()

# Train the model using the vectorized training data
print("\n--- Training the Model ---")
model.fit(X_train_vectorized, y_train)
print("Model training complete.")

"""
## 5. Model Evaluation

Now, we evaluate the trained model's performance on the unseen test data.
We will use accuracy, a classification report (precision, recall, f1-score), and a confusion matrix.
"""

# Make predictions on the vectorized test data
y_pred = model.predict(X_test_vectorized)

print("\n--- Model Evaluation ---")

# Calculate Accuracy Score
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Generate Classification Report
# The report shows precision, recall, f1-score for each class.
# '0' corresponds to 'ham', '1' corresponds to 'spam'
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))

# Generate Confusion Matrix
# A confusion matrix shows the number of correct and incorrect predictions.
# Rows: actual labels, Columns: predicted labels
# [[True Negatives (ham correctly predicted as ham), False Positives (ham predicted as spam)]
#  [False Negatives (spam predicted as ham), True Positives (spam correctly predicted as spam)]]
conf_matrix = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted Ham', 'Predicted Spam'],
            yticklabels=['Actual Ham', 'Actual Spam'])
plt.title('Confusion Matrix for Spam Detection')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""
## 6. Prediction Example

Let's see how the trained model performs on new, unseen email texts.
"""

print("\n--- Making Predictions on New Emails ---")

new_emails = [
    "You won a million dollars! Claim your prize now.", # Should be spam
    "Hi, just confirming our meeting for next Tuesday.", # Should be ham
    "Free money! Click this link to get rich.",           # Should be spam
    "Regarding the project update, please see attached.", # Should be ham
    "Your account is suspended. Verify immediately for security." # Should be spam
]

# Vectorize the new emails using the *same* vectorizer fitted on training data
new_emails_vectorized = vectorizer.transform(new_emails)

# Predict the labels for the new emails
new_predictions = model.predict(new_emails_vectorized)

# Map numerical predictions back to 'ham'/'spam' labels
prediction_labels = ['spam' if pred == 1 else 'ham' for pred in new_predictions]

for i, email in enumerate(new_emails):
    print(f"Email: \"{email}\"\nPredicted: {prediction_labels[i]}\n")

"""
## Summary

This script successfully demonstrates the process of building a simple spam detection model:
1.  **Data Preparation**: Creating a synthetic dataset and splitting it.
2.  **Text Vectorization**: Using `CountVectorizer` to transform text into numerical features.
3.  **Model Training**: Training a `MultinomialNB` classifier.
4.  **Evaluation**: Assessing model performance with accuracy, classification report, and confusion matrix.
5.  **Prediction**: Showing how to use the trained model for new inputs.

This serves as a foundational example for more complex text classification tasks.
"""
